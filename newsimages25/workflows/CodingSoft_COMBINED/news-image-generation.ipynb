{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12714602,"sourceType":"datasetVersion","datasetId":8036075}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1) Install deps\n!pip install -q diffusers==0.30.0 transformers==4.44.2 accelerate==0.33.0 safetensors pillow tqdm pandas","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T12:43:35.993324Z","iopub.execute_input":"2025-08-11T12:43:35.993560Z","iopub.status.idle":"2025-08-11T12:45:04.536909Z","shell.execute_reply.started":"2025-08-11T12:43:35.993542Z","shell.execute_reply":"2025-08-11T12:45:04.536178Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# 2) Imports and strong silencing\nimport os\nimport sys\nimport logging\nfrom pathlib import Path\nimport zipfile\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torch\n\n# Environment-level silencing BEFORE importing diffusers/transformers\nos.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"   # HF hub\nos.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\"\nos.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\nos.environ[\"DIFFUSERS_VERBOSITY\"] = \"error\"        # diffusers internal\nos.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"        # prevent rich progress\nos.environ[\"ACCELERATE_LOG_LEVEL\"] = \"ERROR\"\nos.environ[\"TQDM_DISABLE\"] = \"1\"                   # disable any nested tqdm that libs might spawn\n\n# Silence python loggers\nfor name in [\n    \"diffusers\",\n    \"transformers\",\n    \"accelerate\",\n    \"urllib3\",\n    \"filelock\",\n    \"torch\",\n    \"huggingface_hub\",\n]:\n    logging.getLogger(name).setLevel(logging.ERROR)\nlogging.getLogger().setLevel(logging.ERROR)\n\n# 3) Import pipelines after env is set\nfrom diffusers import AutoPipelineForText2Image\nfrom transformers.utils import logging as hf_logging\nhf_logging.set_verbosity_error()\n\n# Helper: context manager to suppress stdout/stderr temporarily (for model calls)\nimport contextlib\n@contextlib.contextmanager\ndef suppress_stdout_stderr():\n    with open(os.devnull, 'w') as devnull:\n        old_stdout, old_stderr = sys.stdout, sys.stderr\n        try:\n            sys.stdout, sys.stderr = devnull, devnull\n            yield\n        finally:\n            sys.stdout, sys.stderr = old_stdout, old_stderr\n\n# 4) Config\nCSV_PATH = \"/kaggle/input/newsimagedataset-v2/newsarticles.csv\"   # change if needed\nGROUP_NAME = \"CodingSoft\"\nAPPROACH_NAME = \"SDTURBO\"\nTASK_TYPE = \"GEN\"\nOUTPUT_BASE = Path(\"/kaggle/working/output_images\")\nHEIGHT, WIDTH = 260, 460\n\nOUTPUT_LARGE = OUTPUT_BASE / f\"{TASK_TYPE}_{APPROACH_NAME}_LARGE\"\nOUTPUT_SMALL = OUTPUT_BASE / f\"{TASK_TYPE}_{APPROACH_NAME}_SMALL\"\nOUTPUT_LARGE.mkdir(parents=True, exist_ok=True)\nOUTPUT_SMALL.mkdir(parents=True, exist_ok=True)\n\n# 5) Load model quietly\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nwith suppress_stdout_stderr():\n    pipe = AutoPipelineForText2Image.from_pretrained(\n        \"stabilityai/sd-turbo\",\n        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n    ).to(device)\n\n# Disable any progress callbacks and safety prints\n# Many pipelines accept guidance on progress via callbacks, we won't use them.\n# We’ll also avoid enable_model_cpu_offload logs & similar.\n# If needed: pipe.set_progress_bar_config(disable=True) — diffusers supports it in some versions.\ntry:\n    pipe.set_progress_bar_config(disable=True)\nexcept Exception:\n    pass\n\n# 6) Prepare data\ndf = pd.read_csv(CSV_PATH)\n\nstyle_suffix = \"in style of digital illustration, high detail, non photo-realistic\"\ndf[\"prompt\"] = df[\"article_title\"].fillna('') + \" \" + df[\"article_tags\"].fillna('') + \", \" + style_suffix\n\n# Load subset IDs for SMALL folder\nSMALL_CSV_PATH = \"/kaggle/input/newsimagedataset-v2/subset.csv\"  # change if needed\nsmall_df = pd.read_csv(SMALL_CSV_PATH, header=None, usecols=[0])\nsmall_ids = set(small_df[0].astype(str))\n\ndf[\"article_id\"] = df[\"article_id\"].astype(str)\n\n# 7) One global progress bar, no internal bars\ntotal = len(df)\ngen_height, gen_width = 264, 464  # divisible by 8, then resize to 460x260\n\n# Optional memory tweaks\n# pipe.enable_attention_slicing()\n# pipe.enable_vae_slicing()\n\n# We also wrap the per-image call in suppress_stdout_stderr() to kill any residual prints/bars\nwith tqdm(total=total, desc=\"Generating images\", leave=True) as pbar:\n    for idx in range(total):\n        row = df.iloc[idx]\n        article_id = row[\"article_id\"]\n        prompt = row[\"prompt\"]\n\n        with suppress_stdout_stderr():\n            out = pipe(\n                prompt,\n                height=gen_height,\n                width=gen_width,\n                guidance_scale=0.0,\n                num_inference_steps=2  # keep same behavior\n            )\n        image = out.images[0]\n\n        image = image.resize((WIDTH, HEIGHT), Image.LANCZOS)\n\n        filename = f\"{article_id}_{GROUP_NAME}_{APPROACH_NAME}.png\"\n        image.save(OUTPUT_LARGE / filename)\n\n        if article_id in small_ids:\n            image.save(OUTPUT_SMALL / filename)\n\n        pbar.update(1)\n\n# 8) Create required submission ZIP\nZIP_PATH = Path(f\"/kaggle/working/{GROUP_NAME}.zip\")\nwith zipfile.ZipFile(ZIP_PATH, 'w') as zipf:\n    for img_file in OUTPUT_LARGE.iterdir():\n        zipf.write(img_file, arcname=f\"{TASK_TYPE}_{APPROACH_NAME}_LARGE/{img_file.name}\")\n    for img_file in OUTPUT_SMALL.iterdir():\n        zipf.write(img_file, arcname=f\"{TASK_TYPE}_{APPROACH_NAME}_SMALL/{img_file.name}\")\n\nprint(f\"✅ Submission ZIP ready: {ZIP_PATH}\")\n\n# 9) Optional: full working archive like your original\nimport shutil\nparent_folder = \"/kaggle/working/\"\nzip_path = \"/kaggle/working/CodingSoft\"\nshutil.make_archive(zip_path, \"zip\", parent_folder)\nprint(f\"📦 Full working archive: {zip_path}.zip\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T12:45:04.538573Z","iopub.execute_input":"2025-08-11T12:45:04.538778Z","iopub.status.idle":"2025-08-11T13:29:40.978855Z","shell.execute_reply.started":"2025-08-11T12:45:04.538757Z","shell.execute_reply":"2025-08-11T13:29:40.978146Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n/usr/local/lib/python3.11/dist-packages/accelerate/utils/imports.py:282: UserWarning: `ACCELERATE_DISABLE_RICH` is deprecated and will be removed in v0.22.0 and deactivated by default. Please use `ACCELERATE_ENABLE_RICH` if you wish to use `rich`.\n  warnings.warn(\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754916313.532820      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754916313.599622      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8d3f1104cd04c89b6ecdd683e4f7827"}},"metadata":{}},{"name":"stderr","text":"Generating images: 100%|██████████| 8500/8500 [42:24<00:00,  3.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ Submission ZIP ready: /kaggle/working/CodingSoft.zip\n📦 Full working archive: /kaggle/working/CodingSoft.zip\n","output_type":"stream"}],"execution_count":2}]}